name: llm
services:
  searxng:
    container_name: searxng
    image: searxng/searxng
    restart: always
    environment:
      - INSTANCE_NAME=smissingham
      - BASE_URL="https://searxng.${ROOT_DOMAIN}"
    volumes:
      - ${APP_DATA}/llm/searxng:/etc/searxng
    labels:
      - traefik.enable=true
      - traefik.http.routers.searxng.rule=Host(`searxng.${ROOT_DOMAIN}`)
      - traefik.http.routers.searxng.tls=true
      - traefik.http.routers.searxng.entrypoints=websecure
      - traefik.http.routers.searxng.tls.certresolver=resolver
      - traefik.http.services.searxng.loadbalancer.server.port=8080

  open-webui:
    container_name: open-webui
    image: ghcr.io/open-webui/open-webui:main
    restart: always
    environment:
      # Options: https://docs.openwebui.com/getting-started/env-configuration/
      - TZ=${TZ}
      #- OLLAMA_BASE_URL=http://ollama:11434

      - WEBUI_AUTH=False
      - WEBUI_URL=https://chat.${ROOT_DOMAIN}

      - ENABLE_WEB_SEARCH=True
      - WEB_SEARCH_ENGINE=searxng
      - SEARXNG_QUERY_URL=http://searxng:8080/search?q=<query>

      - ENABLE_OPENAI_API=True
      - OPENAI_API_BASE_URL=https://litellm.${ROOT_DOMAIN}/v1
    volumes:
      - ${APP_DATA}/llm/open-webui:/app/backend/data
    depends_on:
      - ollama
      - litellm
    labels:
      - traefik.enable=true
      - traefik.http.routers.openwebui.rule=Host(`chat.${ROOT_DOMAIN}`)
      - traefik.http.routers.openwebui.tls=true
      - traefik.http.routers.openwebui.entrypoints=websecure
      - traefik.http.routers.openwebui.tls.certresolver=resolver
      - traefik.http.services.openwebui.loadbalancer.server.port=8080

  ollama:
    container_name: ollama
    image: ollama/ollama
    restart: always
    hostname: ollama
    environment:
      - TZ=${TZ}
      - OLLAMA_KEEP_ALIVE=24h
    volumes:
      - ${APP_DATA}/llm/ollama:/root/.ollama
    devices:
      - nvidia.com/gpu=all
    labels:
      - traefik.enable=true
      - traefik.http.routers.ollama.rule=Host(`ollama.${ROOT_DOMAIN}`)
      - traefik.http.routers.ollama.tls=true
      - traefik.http.routers.ollama.entrypoints=websecure
      - traefik.http.routers.ollama.tls.certresolver=resolver
      - traefik.http.services.ollama.loadbalancer.server.port=11434

  litellm:
    container_name: litellm
    restart: always
    image: ghcr.io/berriai/litellm:main-latest
    env_file: ".env"
    # ports:
    #   - "4000:4000"
    volumes:
      - ${APP_CONFIG}/llm/litellm/config:/config
    command:
      - --config=/config/config.yaml
    labels:
      - traefik.enable=true
      - traefik.http.routers.litellm.rule=Host(`litellm.${ROOT_DOMAIN}`)
      - traefik.http.routers.litellm.tls=true
      - traefik.http.routers.litellm.entrypoints=websecure
      - traefik.http.routers.litellm.tls.certresolver=resolver
      - traefik.http.services.litellm.loadbalancer.server.port=4000
